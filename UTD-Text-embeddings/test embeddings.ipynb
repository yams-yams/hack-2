{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import distances_from_embeddings, cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start apply\n",
      "end apply\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                text  n_tokens  \\\n0  atalog.utdallas.edu 2013 graduate admission re...       464   \n1  Academic Good Standing Registration in the gra...       490   \n2  Paying Fees as a Part of Registration A studen...       465   \n3  The following guidelines describe whether or n...       501   \n4  Such courses with an earned grade of 'B' or be...       493   \n\n                                          embeddings  \n0  [-0.006768117658793926, -0.018370606005191803,...  \n1  [0.017427491024136543, -0.014574022963643074, ...  \n2  [9.117217996390536e-05, -0.014734090305864811,...  \n3  [0.0068955812603235245, -0.008433591574430466,...  \n4  [-0.005029195919632912, -0.016063299030065536,...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>n_tokens</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>atalog.utdallas.edu 2013 graduate admission re...</td>\n      <td>464</td>\n      <td>[-0.006768117658793926, -0.018370606005191803,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Academic Good Standing Registration in the gra...</td>\n      <td>490</td>\n      <td>[0.017427491024136543, -0.014574022963643074, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Paying Fees as a Part of Registration A studen...</td>\n      <td>465</td>\n      <td>[9.117217996390536e-05, -0.014734090305864811,...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The following guidelines describe whether or n...</td>\n      <td>501</td>\n      <td>[0.0068955812603235245, -0.008433591574430466,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Such courses with an earned grade of 'B' or be...</td>\n      <td>493</td>\n      <td>[-0.005029195919632912, -0.016063299030065536,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('processed/embeddings.csv', index_col=0)\n",
    "print(\"start apply\")\n",
    "df['embeddings'] = df['embeddings'].apply(eval).apply(np.array)\n",
    "print(\"end apply\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "openai.api_key = 'APIKEY'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "\n",
    "def create_context(\n",
    "        question, df, max_len=1800, size=\"ada\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a context for a question by finding the most similar context from the dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the embeddings for the question\n",
    "    # print(\"Start embeddings\")\n",
    "    q_embeddings = openai.Embedding.create(input=question, engine='text-embedding-ada-002')['data'][0]['embedding']\n",
    "    # print(\"End embeddings\")\n",
    "    # Get the distances from the embeddings\n",
    "    # print(\"Start calculating cosine similarity\")\n",
    "    df['distances'] = distances_from_embeddings(q_embeddings, df['embeddings'].values, distance_metric='cosine')\n",
    "    # print(\"End calculating cosine similarity\")\n",
    "    returns = []\n",
    "    cur_len = 0\n",
    "\n",
    "    # Sort by distance and add the text to the context until the context is too long\n",
    "    # print(\"start sort by distance\")\n",
    "    for i, row in df.sort_values('distances', ascending=True).iterrows():\n",
    "\n",
    "        # Add the length of the text to the current length\n",
    "        cur_len += row['n_tokens'] + 4\n",
    "\n",
    "        # If the context is too long, break\n",
    "        if cur_len > max_len:\n",
    "            break\n",
    "\n",
    "        # Else add it to the text that is being returned\n",
    "        returns.append(row[\"text\"])\n",
    "\n",
    "    # Return the context\n",
    "    return \"\\n\\n###\\n\\n\".join(returns)\n",
    "\n",
    "\n",
    "def answer_question(\n",
    "        df,\n",
    "        model=\"text-davinci-003\",\n",
    "        question=\"What classes do I need to take to graduate?\",\n",
    "        max_len=1800,\n",
    "        size=\"ada\",\n",
    "        debug=False,\n",
    "        max_tokens=150,\n",
    "        stop_sequence=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Answer a question based on the most similar context from the dataframe texts\n",
    "    \"\"\"\n",
    "    context = create_context(\n",
    "        question,\n",
    "        df,\n",
    "        max_len=max_len,\n",
    "        size=size,\n",
    "    )\n",
    "    # print(\"end sort by distance\")\n",
    "    # If debug, print the raw model response\n",
    "    if debug:\n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a completions using the questin and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"Unfortunately, I have not been trained to answer that question yet (If you would like to help finacially support the text embedding process, please contact the creators after this presentation)\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {question}\\nAnswer:\",\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### Step 13\n",
    "################################################################################\n",
    "\n",
    "def askGPT(question, messages):\n",
    "\n",
    "    textcompletions = answer_question(df, question=question, debug=False)\n",
    "    messages.append({\"role\": \"user\", \"content\": f\"{question} ### text embeddings: {textcompletions}\"})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    messages.append(\n",
    "        {\"role\": response['choices'][0]['message']['role'],\"content\": response['choices'][0]['message']['content']}\n",
    "    )\n",
    "    return {response['choices'][0]['message']['content']}\n",
    "#\n",
    "# print(answer_question(df, question=\"How can I start the graduation process?\", debug=False))\n",
    "#\n",
    "# print(answer_question(df, question=\"What are the core courses that I have to take?\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am GradGuide, your personal AI academic advisor. Can I help you with anything today?\n",
      "\n",
      "{'Hello! How can I assist you today with academic advising at UTD?'}\n",
      "\n",
      "{'I apologize for the confusion earlier. Is there anything I can help you with regarding academic advising at UTD?'}\n",
      "\n",
      "{'To know if you can graduate from UTD, you should regularly check your degree plan and meet with your academic advisor to ensure that you have completed all required coursework and met all degree requirements. Typically, students must complete all required coursework with passing grades and maintain a minimum GPA in both their major and overall coursework. Once you have met all the necessary requirements, the university will review your academic record, and if you meet all the criteria for graduation, you will be awarded your degree.'}\n",
      "\n",
      "{'Is there anything else I can help you with regarding academic advising at UTD?'}\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [19], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m myQn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28minput\u001B[39m()\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43maskGPT\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmyQn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn [15], line 86\u001B[0m, in \u001B[0;36maskGPT\u001B[1;34m(question, messages)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maskGPT\u001B[39m(question, messages):\n\u001B[1;32m---> 86\u001B[0m     textcompletions \u001B[38;5;241m=\u001B[39m \u001B[43manswer_question\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m     messages\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquestion\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ### text embeddings: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtextcompletions\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m})\n\u001B[0;32m     88\u001B[0m     response \u001B[38;5;241m=\u001B[39m openai\u001B[38;5;241m.\u001B[39mChatCompletion\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m     89\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     90\u001B[0m         messages\u001B[38;5;241m=\u001B[39mmessages\n\u001B[0;32m     91\u001B[0m     )\n",
      "Cell \u001B[1;32mIn [15], line 50\u001B[0m, in \u001B[0;36manswer_question\u001B[1;34m(df, model, question, max_len, size, debug, max_tokens, stop_sequence)\u001B[0m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21manswer_question\u001B[39m(\n\u001B[0;32m     38\u001B[0m         df,\n\u001B[0;32m     39\u001B[0m         model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-davinci-003\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     45\u001B[0m         stop_sequence\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     46\u001B[0m ):\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;124;03m    Answer a question based on the most similar context from the dataframe texts\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m     context \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m        \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;66;03m# print(\"end sort by distance\")\u001B[39;00m\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;66;03m# If debug, print the raw model response\u001B[39;00m\n\u001B[0;32m     58\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug:\n",
      "Cell \u001B[1;32mIn [15], line 14\u001B[0m, in \u001B[0;36mcreate_context\u001B[1;34m(question, df, max_len, size)\u001B[0m\n\u001B[0;32m     10\u001B[0m q_embeddings \u001B[38;5;241m=\u001B[39m openai\u001B[38;5;241m.\u001B[39mEmbedding\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39mquestion, engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext-embedding-ada-002\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# print(\"End embeddings\")\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# Get the distances from the embeddings\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# print(\"Start calculating cosine similarity\")\u001B[39;00m\n\u001B[1;32m---> 14\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdistances\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdistances_from_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq_embeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43membeddings\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcosine\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# print(\"End calculating cosine similarity\")\u001B[39;00m\n\u001B[0;32m     16\u001B[0m returns \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\Desktop\\Island-Satisfiability\\lib\\site-packages\\openai\\embeddings_utils.py:153\u001B[0m, in \u001B[0;36mdistances_from_embeddings\u001B[1;34m(query_embedding, embeddings, distance_metric)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;124;03m\"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\u001B[39;00m\n\u001B[0;32m    147\u001B[0m distance_metrics \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcosine\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39mcosine,\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL1\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39mcityblock,\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL2\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39meuclidean,\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLinf\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39mchebyshev,\n\u001B[0;32m    152\u001B[0m }\n\u001B[1;32m--> 153\u001B[0m distances \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    154\u001B[0m     distance_metrics[distance_metric](query_embedding, embedding)\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m embedding \u001B[38;5;129;01min\u001B[39;00m embeddings\n\u001B[0;32m    156\u001B[0m ]\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m distances\n",
      "File \u001B[1;32m~\\Desktop\\Island-Satisfiability\\lib\\site-packages\\openai\\embeddings_utils.py:154\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;124;03m\"\"\"Return the distances between a query embedding and a list of embeddings.\"\"\"\u001B[39;00m\n\u001B[0;32m    147\u001B[0m distance_metrics \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcosine\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39mcosine,\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL1\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39mcityblock,\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL2\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39meuclidean,\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLinf\u001B[39m\u001B[38;5;124m\"\u001B[39m: spatial\u001B[38;5;241m.\u001B[39mdistance\u001B[38;5;241m.\u001B[39mchebyshev,\n\u001B[0;32m    152\u001B[0m }\n\u001B[0;32m    153\u001B[0m distances \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 154\u001B[0m     \u001B[43mdistance_metrics\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdistance_metric\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m embedding \u001B[38;5;129;01min\u001B[39;00m embeddings\n\u001B[0;32m    156\u001B[0m ]\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m distances\n",
      "File \u001B[1;32m~\\Desktop\\Island-Satisfiability\\lib\\site-packages\\scipy\\spatial\\distance.py:678\u001B[0m, in \u001B[0;36mcosine\u001B[1;34m(u, v, w)\u001B[0m\n\u001B[0;32m    636\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001B[39;00m\n\u001B[0;32m    638\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    673\u001B[0m \n\u001B[0;32m    674\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    675\u001B[0m \u001B[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001B[39;00m\n\u001B[0;32m    676\u001B[0m \u001B[38;5;66;03m#   or 'reflective correlation'\u001B[39;00m\n\u001B[0;32m    677\u001B[0m \u001B[38;5;66;03m# clamp the result to 0-2\u001B[39;00m\n\u001B[1;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mmin\u001B[39m(\u001B[43mcorrelation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcentered\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m, \u001B[38;5;241m2.0\u001B[39m))\n",
      "File \u001B[1;32m~\\Desktop\\Island-Satisfiability\\lib\\site-packages\\scipy\\spatial\\distance.py:627\u001B[0m, in \u001B[0;36mcorrelation\u001B[1;34m(u, v, w, centered)\u001B[0m\n\u001B[0;32m    625\u001B[0m     u \u001B[38;5;241m=\u001B[39m u \u001B[38;5;241m-\u001B[39m umu\n\u001B[0;32m    626\u001B[0m     v \u001B[38;5;241m=\u001B[39m v \u001B[38;5;241m-\u001B[39m vmu\n\u001B[1;32m--> 627\u001B[0m uv \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    628\u001B[0m uu \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage(np\u001B[38;5;241m.\u001B[39msquare(u), weights\u001B[38;5;241m=\u001B[39mw)\n\u001B[0;32m    629\u001B[0m vv \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage(np\u001B[38;5;241m.\u001B[39msquare(v), weights\u001B[38;5;241m=\u001B[39mw)\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36maverage\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\Desktop\\Island-Satisfiability\\lib\\site-packages\\numpy\\lib\\function_base.py:518\u001B[0m, in \u001B[0;36maverage\u001B[1;34m(a, axis, weights, returned, keepdims)\u001B[0m\n\u001B[0;32m    515\u001B[0m     keepdims_kw \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkeepdims\u001B[39m\u001B[38;5;124m'\u001B[39m: keepdims}\n\u001B[0;32m    517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 518\u001B[0m     avg \u001B[38;5;241m=\u001B[39m a\u001B[38;5;241m.\u001B[39mmean(axis, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkeepdims_kw)\n\u001B[0;32m    519\u001B[0m     scl \u001B[38;5;241m=\u001B[39m avg\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype(a\u001B[38;5;241m.\u001B[39msize\u001B[38;5;241m/\u001B[39mavg\u001B[38;5;241m.\u001B[39msize)\n\u001B[0;32m    520\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\Island-Satisfiability\\lib\\site-packages\\numpy\\core\\_methods.py:180\u001B[0m, in \u001B[0;36m_mean\u001B[1;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[0;32m    177\u001B[0m         dtype \u001B[38;5;241m=\u001B[39m mu\u001B[38;5;241m.\u001B[39mdtype(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    178\u001B[0m         is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 180\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mumr_sum\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(ret, mu\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m    182\u001B[0m     ret \u001B[38;5;241m=\u001B[39m um\u001B[38;5;241m.\u001B[39mtrue_divide(\n\u001B[0;32m    183\u001B[0m             ret, rcount, out\u001B[38;5;241m=\u001B[39mret, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m'\u001B[39m, subok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": f\"You are an AI academic advisor named GradGuide that has been trained on text embeddings of the UT Dallas catalogs. Use text embeddings to inform your responses\"}]\n",
    "print(\"Hello, I am GradGuide, your personal AI academic advisor. Can I help you with anything today?\")\n",
    "while True:\n",
    "    myQn = input()\n",
    "    print(\"\")\n",
    "    print(askGPT(myQn, messages))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}